{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ebbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'tag wiki-formatted.txt'\n",
    "with open(filename,'r',encoding='UTF-8') as fp:\n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf41597",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1=[]\n",
    "for line in lines:\n",
    "    line = eval(line)\n",
    "    result_1.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0800ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tup_list = [tuple(item.items()) for item in result_1]\n",
    "sets = {t for t in tup_list}\n",
    "result_2 = [dict(t) for t in sets]\n",
    "\n",
    "# print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  extract all subtrees marked as NP\n",
    "def extract_np_subtrees(text):\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    # A block analyzerbased on regular expressions\n",
    "    chunk_parser = nltk.RegexpParser(r\" NP:{<NN.*>}\")\n",
    "    # perform chunking analysis on already annotated text\n",
    "    tree = chunk_parser.parse(tagged)\n",
    "    return [subtree for subtree in tree.subtrees() if subtree.label() == 'NP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3=[]\n",
    "for item in result_2:\n",
    "    for k,v in item.items():\n",
    "#         if len(v)<=1 or v.endswith('yet!'):\n",
    "#             break\n",
    "        temp={k:[]}\n",
    "        np_subtrees = extract_np_subtrees(v)\n",
    "        for subtree in np_subtrees:\n",
    "            pos= subtree.leaves()\n",
    "            temp[k].append(pos[0][0])\n",
    "        result_3.append(temp)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../recommend-output.csv')\n",
    "formLibList = list(df['fromLib'])\n",
    "toLibList = list(df['toLib'])\n",
    "confidenceList = list(df['confidence'])\n",
    "confirmedList = list(df['isConfirmed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagAll=[]\n",
    "n = len(formLibList)\n",
    "for i in range(n):\n",
    "    item=[]\n",
    "    item.append(formLibList[i])\n",
    "    item.append(toLibList[i])\n",
    "    item.append(confidenceList[i])\n",
    "    item.append(confirmedList[i])\n",
    "    tagAll.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tagAll))\n",
    "print(tagAll[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item1 in tagAll:\n",
    "    for item2 in result_3:\n",
    "        lib1 = item1[0].split(':')[1]\n",
    "        lib2 = list(item2.keys())[0]\n",
    "        if lib1==lib2 :\n",
    "            item1.insert(1,item2[lib2])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tagAll))\n",
    "print(tagAll[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multiple operations are required to completely delete items with a length less than 5\n",
    "'''\n",
    "for item in tagAll:\n",
    "    if len(item)<5:\n",
    "        tagAll.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbe602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(tagAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item1 in tagAll:\n",
    "    for item2 in result_3:\n",
    "        try:\n",
    "            lib1 = item1[2].split(':')[1]\n",
    "            lib2 = list(item2.keys())[0]\n",
    "            if lib1==lib2 :\n",
    "                item1.insert(3,item2[lib2])\n",
    "                break\n",
    "        except IndexError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7fbe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tagAll:\n",
    "    if len(item)<6:\n",
    "        tagAll.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2776fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tagAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tagAll[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_common_words(s1, s2):\n",
    "    set1 = set(s1)\n",
    "    set2 = set(s2)\n",
    "    common_words = set1.intersection(set2)\n",
    "    return len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tagAll:\n",
    "    num = count_common_words(item[1],item[3])\n",
    "    if num==0:\n",
    "        item.append(1)\n",
    "    else:\n",
    "        item.append(1.5 * num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tagAll))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f533fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tagAll:\n",
    "    item[1] = ','.join(item[1])\n",
    "    item[3] = ','.join(item[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a65b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tagAll[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ccc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = tagAll\n",
    "df = pd.DataFrame(data, columns= \n",
    "                  ['fromLib', 'fromLabels', 'toLib', 'toLabels','confidence','isConfirmed','labelSupport'])\n",
    "df.to_excel(r'../resources/tag wiki.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
